#!/usr/bin/env python3
"""
QwenRag ä»£ç è¯„ä¼°è„šæœ¬

åŠŸèƒ½:
- ç»Ÿè®¡æºä»£ç è¡Œæ•°
- ç»Ÿè®¡æµ‹è¯•ä»£ç è¡Œæ•°  
- ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
- è¾“å‡ºé¡¹ç›®ä»£ç è´¨é‡æŒ‡æ ‡
"""

import os
import sys
import subprocess
import json
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


@dataclass
class CodeStats:
    """ä»£ç ç»Ÿè®¡ä¿¡æ¯"""
    total_lines: int = 0
    code_lines: int = 0
    comment_lines: int = 0
    blank_lines: int = 0
    files_count: int = 0


@dataclass
class ProjectStats:
    """é¡¹ç›®ç»Ÿè®¡ä¿¡æ¯"""
    source_code: CodeStats
    test_code: CodeStats
    config_files: CodeStats
    documentation: CodeStats
    total_files: int = 0


class CodeEvaluator:
    """ä»£ç è¯„ä¼°å™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.source_dirs = ['processors', 'vector_store', 'schemas', 'utils']
        self.test_dirs = ['tests']
        self.config_files = ['config.py', 'main_index.py', 'main_search.py', 'demo.py']
        self.doc_files = ['*.md', '*.rst', '*.txt']
        self.exclude_dirs = {'.git', '__pycache__', '.pytest_cache', 'node_modules', '.venv', 'venv'}
        
    def count_lines_in_file(self, file_path: Path) -> CodeStats:
        """ç»Ÿè®¡å•ä¸ªæ–‡ä»¶çš„è¡Œæ•°"""
        stats = CodeStats(files_count=1)
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            stats.total_lines = len(lines)
            
            for line in lines:
                stripped = line.strip()
                if not stripped:
                    stats.blank_lines += 1
                elif stripped.startswith('#') or stripped.startswith('"""') or stripped.startswith("'''"):
                    stats.comment_lines += 1
                else:
                    # æ£€æŸ¥è¡Œå†…æ³¨é‡Š
                    if '#' in stripped and not stripped.startswith('"') and not stripped.startswith("'"):
                        stats.code_lines += 1  # æœ‰ä»£ç çš„è¡Œ
                    else:
                        stats.code_lines += 1
                        
        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            
        return stats
    
    def scan_directory(self, directory: Path, file_extensions: List[str] = None) -> CodeStats:
        """æ‰«æç›®å½•å¹¶ç»Ÿè®¡ä»£ç è¡Œæ•°"""
        if file_extensions is None:
            file_extensions = ['.py']
            
        total_stats = CodeStats()
        
        if not directory.exists():
            return total_stats
            
        for file_path in directory.rglob('*'):
            if file_path.is_file() and file_path.suffix in file_extensions:
                # æ’é™¤ç‰¹å®šç›®å½•
                if any(exclude_dir in file_path.parts for exclude_dir in self.exclude_dirs):
                    continue
                    
                file_stats = self.count_lines_in_file(file_path)
                total_stats.total_lines += file_stats.total_lines
                total_stats.code_lines += file_stats.code_lines
                total_stats.comment_lines += file_stats.comment_lines
                total_stats.blank_lines += file_stats.blank_lines
                total_stats.files_count += file_stats.files_count
                
        return total_stats
    
    def get_source_code_stats(self) -> CodeStats:
        """è·å–æºä»£ç ç»Ÿè®¡"""
        total_stats = CodeStats()
        
        for dir_name in self.source_dirs:
            dir_path = self.project_root / dir_name
            dir_stats = self.scan_directory(dir_path)
            total_stats.total_lines += dir_stats.total_lines
            total_stats.code_lines += dir_stats.code_lines
            total_stats.comment_lines += dir_stats.comment_lines
            total_stats.blank_lines += dir_stats.blank_lines
            total_stats.files_count += dir_stats.files_count
            
        # æ·»åŠ é…ç½®æ–‡ä»¶
        for config_file in self.config_files:
            config_path = self.project_root / config_file
            if config_path.exists():
                file_stats = self.count_lines_in_file(config_path)
                total_stats.total_lines += file_stats.total_lines
                total_stats.code_lines += file_stats.code_lines
                total_stats.comment_lines += file_stats.comment_lines
                total_stats.blank_lines += file_stats.blank_lines
                total_stats.files_count += file_stats.files_count
                
        return total_stats
    
    def get_test_code_stats(self) -> CodeStats:
        """è·å–æµ‹è¯•ä»£ç ç»Ÿè®¡"""
        total_stats = CodeStats()
        
        for dir_name in self.test_dirs:
            dir_path = self.project_root / dir_name
            dir_stats = self.scan_directory(dir_path)
            total_stats.total_lines += dir_stats.total_lines
            total_stats.code_lines += dir_stats.code_lines
            total_stats.comment_lines += dir_stats.comment_lines
            total_stats.blank_lines += dir_stats.blank_lines
            total_stats.files_count += dir_stats.files_count
            
        return total_stats
    
    def get_documentation_stats(self) -> CodeStats:
        """è·å–æ–‡æ¡£ç»Ÿè®¡"""
        total_stats = CodeStats()
        doc_extensions = ['.md', '.rst', '.txt']
        
        for file_path in self.project_root.rglob('*'):
            if file_path.is_file() and file_path.suffix in doc_extensions:
                # æ’é™¤ç‰¹å®šç›®å½•
                if any(exclude_dir in file_path.parts for exclude_dir in self.exclude_dirs):
                    continue
                    
                file_stats = self.count_lines_in_file(file_path)
                total_stats.total_lines += file_stats.total_lines
                total_stats.code_lines += file_stats.code_lines
                total_stats.comment_lines += file_stats.comment_lines
                total_stats.blank_lines += file_stats.blank_lines
                total_stats.files_count += file_stats.files_count
                
        return total_stats
    
    def run_coverage_analysis(self) -> Dict:
        """è¿è¡Œæµ‹è¯•è¦†ç›–ç‡åˆ†æ"""
        coverage_data = {
            'coverage_percentage': 0,
            'total_statements': 0,
            'covered_statements': 0,
            'missing_lines': 0,
            'files_coverage': {},
            'error': None
        }
        
        try:
            # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†coverage
            subprocess.run(['python3', '-c', 'import coverage'], 
                         check=True, capture_output=True, cwd=self.project_root)
            
            # è¿è¡Œå¸¦è¦†ç›–ç‡çš„æµ‹è¯•
            print("æ­£åœ¨è¿è¡Œæµ‹è¯•è¦†ç›–ç‡åˆ†æ...")
            result = subprocess.run([
                'python3', '-m', 'pytest', 'tests/', 
                '--cov=.', '--cov-report=json', '--cov-report=term-missing', '-q'
            ], capture_output=True, text=True, cwd=self.project_root)
            
            if result.returncode == 0:
                # è¯»å–coverage.jsonæ–‡ä»¶
                coverage_file = self.project_root / 'coverage.json'
                if coverage_file.exists():
                    with open(coverage_file, 'r') as f:
                        cov_data = json.load(f)
                    
                    # è§£æè¦†ç›–ç‡æ•°æ®
                    totals = cov_data.get('totals', {})
                    coverage_data['coverage_percentage'] = totals.get('percent_covered', 0)
                    coverage_data['total_statements'] = totals.get('num_statements', 0)
                    coverage_data['covered_statements'] = totals.get('covered_lines', 0)
                    coverage_data['missing_lines'] = totals.get('missing_lines', 0)
                    
                    # æ–‡ä»¶çº§åˆ«çš„è¦†ç›–ç‡
                    files = cov_data.get('files', {})
                    for file_path, file_data in files.items():
                        if not any(exclude in file_path for exclude in ['test_', '__pycache__', '.git']):
                            coverage_data['files_coverage'][file_path] = {
                                'coverage': file_data.get('summary', {}).get('percent_covered', 0),
                                'statements': file_data.get('summary', {}).get('num_statements', 0),
                                'missing': len(file_data.get('missing_lines', []))
                            }
                    
                    print(f"æµ‹è¯•è¦†ç›–ç‡åˆ†æå®Œæˆ: {coverage_data['coverage_percentage']:.1f}%")
                else:
                    coverage_data['error'] = "æœªæ‰¾åˆ°coverage.jsonæ–‡ä»¶"
            else:
                coverage_data['error'] = f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {result.stderr}"
                
        except subprocess.CalledProcessError:
            coverage_data['error'] = "coverageæ¨¡å—æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install coverage"
        except Exception as e:
            coverage_data['error'] = f"è¦†ç›–ç‡åˆ†æå¤±è´¥: {str(e)}"
            
        return coverage_data
    
    def get_project_complexity(self) -> Dict:
        """è·å–é¡¹ç›®å¤æ‚åº¦æŒ‡æ ‡"""
        complexity = {
            'total_functions': 0,
            'total_classes': 0,
            'average_function_length': 0,
            'files_with_high_complexity': []
        }
        
        function_lengths = []
        
        for dir_name in self.source_dirs:
            dir_path = self.project_root / dir_name
            if dir_path.exists():
                for py_file in dir_path.rglob('*.py'):
                    try:
                        with open(py_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # ç»Ÿè®¡å‡½æ•°å’Œç±»
                        functions = re.findall(r'^def\s+\w+', content, re.MULTILINE)
                        classes = re.findall(r'^class\s+\w+', content, re.MULTILINE)
                        
                        complexity['total_functions'] += len(functions)
                        complexity['total_classes'] += len(classes)
                        
                        # ä¼°ç®—å‡½æ•°é•¿åº¦
                        lines = content.split('\n')
                        current_function_start = None
                        indent_level = 0
                        
                        for i, line in enumerate(lines):
                            stripped = line.strip()
                            if stripped.startswith('def '):
                                if current_function_start is not None:
                                    func_length = i - current_function_start
                                    function_lengths.append(func_length)
                                current_function_start = i
                                indent_level = len(line) - len(line.lstrip())
                            elif current_function_start is not None and stripped and len(line) - len(line.lstrip()) <= indent_level and not line.startswith(' '):
                                func_length = i - current_function_start
                                function_lengths.append(func_length)
                                current_function_start = None
                        
                        # æ£€æŸ¥é«˜å¤æ‚åº¦æ–‡ä»¶ (è¶…è¿‡500è¡Œ)
                        if len(lines) > 500:
                            complexity['files_with_high_complexity'].append(str(py_file.relative_to(self.project_root)))
                            
                    except Exception as e:
                        print(f"è­¦å‘Š: åˆ†ææ–‡ä»¶å¤æ‚åº¦å¤±è´¥ {py_file}: {e}")
        
        if function_lengths:
            complexity['average_function_length'] = sum(function_lengths) / len(function_lengths)
            
        return complexity
    
    def generate_report(self) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„è¯„ä¼°æŠ¥å‘Š"""
        print("ğŸ” å¼€å§‹ä»£ç è¯„ä¼°...")
        
        # è·å–ä»£ç ç»Ÿè®¡
        source_stats = self.get_source_code_stats()
        test_stats = self.get_test_code_stats()
        doc_stats = self.get_documentation_stats()
        
        # è·å–æµ‹è¯•è¦†ç›–ç‡
        coverage_data = self.run_coverage_analysis()
        
        # è·å–å¤æ‚åº¦æŒ‡æ ‡
        complexity = self.get_project_complexity()
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        total_code_lines = source_stats.code_lines + test_stats.code_lines
        test_to_code_ratio = test_stats.code_lines / source_stats.code_lines if source_stats.code_lines > 0 else 0
        
        report = {
            'project_summary': {
                'source_files': source_stats.files_count,
                'test_files': test_stats.files_count,
                'documentation_files': doc_stats.files_count,
                'total_files': source_stats.files_count + test_stats.files_count + doc_stats.files_count
            },
            'code_statistics': {
                'source_code': {
                    'total_lines': source_stats.total_lines,
                    'code_lines': source_stats.code_lines,
                    'comment_lines': source_stats.comment_lines,
                    'blank_lines': source_stats.blank_lines,
                    'files': source_stats.files_count
                },
                'test_code': {
                    'total_lines': test_stats.total_lines,
                    'code_lines': test_stats.code_lines,
                    'comment_lines': test_stats.comment_lines,
                    'blank_lines': test_stats.blank_lines,
                    'files': test_stats.files_count
                },
                'documentation': {
                    'total_lines': doc_stats.total_lines,
                    'files': doc_stats.files_count
                }
            },
            'quality_metrics': {
                'test_coverage_percentage': coverage_data['coverage_percentage'],
                'test_to_code_ratio': test_to_code_ratio,
                'total_functions': complexity['total_functions'],
                'total_classes': complexity['total_classes'],
                'average_function_length': complexity['average_function_length'],
                'files_with_high_complexity': complexity['files_with_high_complexity']
            },
            'coverage_details': coverage_data,
            'complexity_analysis': complexity
        }
        
        return report


def print_report(report: Dict):
    """æ ¼å¼åŒ–æ‰“å°æŠ¥å‘Š"""
    print("\n" + "="*80)
    print("ğŸ“Š QwenRag é¡¹ç›®ä»£ç è¯„ä¼°æŠ¥å‘Š")
    print("="*80)
    
    # é¡¹ç›®æ¦‚è§ˆ
    summary = report['project_summary']
    print(f"\nğŸ“ é¡¹ç›®æ¦‚è§ˆ:")
    print(f"   æºä»£ç æ–‡ä»¶: {summary['source_files']}")
    print(f"   æµ‹è¯•æ–‡ä»¶: {summary['test_files']}")
    print(f"   æ–‡æ¡£æ–‡ä»¶: {summary['documentation_files']}")
    print(f"   æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
    
    # ä»£ç ç»Ÿè®¡
    stats = report['code_statistics']
    print(f"\nğŸ“ ä»£ç ç»Ÿè®¡:")
    
    print(f"   æºä»£ç :")
    src = stats['source_code']
    print(f"     æ€»è¡Œæ•°: {src['total_lines']:,}")
    print(f"     ä»£ç è¡Œ: {src['code_lines']:,}")
    print(f"     æ³¨é‡Šè¡Œ: {src['comment_lines']:,}")
    print(f"     ç©ºç™½è¡Œ: {src['blank_lines']:,}")
    
    print(f"   æµ‹è¯•ä»£ç :")
    test = stats['test_code']
    print(f"     æ€»è¡Œæ•°: {test['total_lines']:,}")
    print(f"     ä»£ç è¡Œ: {test['code_lines']:,}")
    print(f"     æ³¨é‡Šè¡Œ: {test['comment_lines']:,}")
    print(f"     ç©ºç™½è¡Œ: {test['blank_lines']:,}")
    
    # è´¨é‡æŒ‡æ ‡
    metrics = report['quality_metrics']
    print(f"\nğŸ“ˆ è´¨é‡æŒ‡æ ‡:")
    print(f"   æµ‹è¯•è¦†ç›–ç‡: {metrics['test_coverage_percentage']:.1f}%")
    print(f"   æµ‹è¯•/ä»£ç æ¯”: {metrics['test_to_code_ratio']:.2f}")
    print(f"   å‡½æ•°æ€»æ•°: {metrics['total_functions']}")
    print(f"   ç±»æ€»æ•°: {metrics['total_classes']}")
    print(f"   å¹³å‡å‡½æ•°é•¿åº¦: {metrics['average_function_length']:.1f} è¡Œ")
    
    if metrics['files_with_high_complexity']:
        print(f"   é«˜å¤æ‚åº¦æ–‡ä»¶: {len(metrics['files_with_high_complexity'])} ä¸ª")
        for file in metrics['files_with_high_complexity']:
            print(f"     - {file}")
    
    # è¦†ç›–ç‡è¯¦æƒ…
    coverage = report['coverage_details']
    if coverage.get('error'):
        print(f"\nâš ï¸  æµ‹è¯•è¦†ç›–ç‡åˆ†æ: {coverage['error']}")
    else:
        print(f"\nğŸ¯ æµ‹è¯•è¦†ç›–ç‡è¯¦æƒ…:")
        print(f"   è¦†ç›–ç‡: {coverage['coverage_percentage']:.1f}%")
        print(f"   æ€»è¯­å¥æ•°: {coverage['total_statements']:,}")
        print(f"   å·²è¦†ç›–è¯­å¥: {coverage['covered_statements']:,}")
        print(f"   æœªè¦†ç›–è¡Œæ•°: {coverage['missing_lines']:,}")
        
        # æ–‡ä»¶çº§è¦†ç›–ç‡ (åªæ˜¾ç¤ºè¦†ç›–ç‡è¾ƒä½çš„æ–‡ä»¶)
        low_coverage_files = {k: v for k, v in coverage.get('files_coverage', {}).items() 
                            if v['coverage'] < 80 and v['statements'] > 10}
        if low_coverage_files:
            print(f"\n   éœ€è¦æ”¹è¿›çš„æ–‡ä»¶ (<80% è¦†ç›–ç‡):")
            for file, data in sorted(low_coverage_files.items(), key=lambda x: x[1]['coverage']):
                print(f"     - {file}: {data['coverage']:.1f}% ({data['missing']} è¡Œæœªè¦†ç›–)")
    
    # å»ºè®®
    print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
    suggestions = []
    
    if metrics['test_coverage_percentage'] < 80:
        suggestions.append(f"   â€¢ æé«˜æµ‹è¯•è¦†ç›–ç‡åˆ°80%ä»¥ä¸Š (å½“å‰: {metrics['test_coverage_percentage']:.1f}%)")
    
    if metrics['test_to_code_ratio'] < 0.5:
        suggestions.append(f"   â€¢ å¢åŠ æµ‹è¯•ä»£ç ï¼Œå»ºè®®æµ‹è¯•/ä»£ç æ¯”è¾¾åˆ°0.5ä»¥ä¸Š (å½“å‰: {metrics['test_to_code_ratio']:.2f})")
    
    if metrics['average_function_length'] > 50:
        suggestions.append(f"   â€¢ è€ƒè™‘é‡æ„è¾ƒé•¿çš„å‡½æ•°ï¼Œå»ºè®®å¹³å‡é•¿åº¦æ§åˆ¶åœ¨50è¡Œä»¥å†… (å½“å‰: {metrics['average_function_length']:.1f}è¡Œ)")
    
    if metrics['files_with_high_complexity']:
        suggestions.append(f"   â€¢ é‡æ„é«˜å¤æ‚åº¦æ–‡ä»¶ï¼Œè€ƒè™‘æ‹†åˆ†ä¸ºæ›´å°çš„æ¨¡å—")
    
    if not suggestions:
        suggestions.append("   â€¢ ä»£ç è´¨é‡è‰¯å¥½ï¼Œç»§ç»­ä¿æŒï¼")
    
    for suggestion in suggestions:
        print(suggestion)
    
    print("\n" + "="*80)


def main():
    """ä¸»å‡½æ•°"""
    project_root = Path(__file__).parent.parent
    evaluator = CodeEvaluator(project_root)
    
    try:
        report = evaluator.generate_report()
        print_report(report)
        
        # ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š
        report_file = project_root / 'eval' / 'code_evaluation_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()